m1 <- matrix(c(T, T, F, F, T, F), nrow = 2)
m1
# Give data, then dimemensions (rows, columns, tables)
a1 <- array(c( 1:24), c(4, 3, 2))
dfa <- cbind(vNumeric, vCharacter, vLogical)
dfa  # Matrix of one data type
dfa <- cbind(vNumeric, vCharacter, vLogical)
vNumeric   <- c(1, 2, 3)
vCharacter <- c("a", "b", "c")
vLogical   <- c(T, F, T)
dfa <- cbind(vNumeric, vCharacter, vLogical)
dfa  # Matrix of one data type
df <- as.data.frame(cbind(vNumeric, vCharacter, vLogical))
df  # Makes a data frame with three different data types
o1 <- c(1, 2, 3)
o2 <- c("a", "b", "c", "d")
o3 <- c(T, F, T, T, F)
list1 <- list(o1, o2, o3)
list1
list1
list2 <- list(o1, o2, o3, list1)  # Lists within lists!
list2
(coerce1 <- c(1, "b", TRUE))
# coerce1  # Parenthese around command above make this moot
typeof(coerce1)
(coerce2 <- 5)
typeof(coerce2)
(coerce3 <- as.integer(5))
typeof(coerce3)
(coerce4 <- c("1", "2", "3"))
typeof(coerce4)
(coerce6 <- matrix(1:9, nrow= 3))
is.matrix(coerce6)
a2 <- array(c(1,2,3,4))
a2
is.array(a2)
# Give data, then dimemensions (rows, columns, tables)
a1 <- array(c( 1:24), c(4, 3, 2))
a1
# Give data, then dimemensions (rows, columns, tables)
a1 <- array(c( 1:24), c(4, 3, 2))
a1
a2 <- array(c(1:20),c(2,3,2))
a2
is.array(a2)
# Give data, then dimemensions (rows, columns, tables)
a1 <- array(c( 1:24), c(4, 3, 2))
a1
a2 <- array(c(1:20),c(2,3,2))
a2
a2 <- array(c(1:10),c(2,5,2))
a2
is.array(a2)
a2 <- array(c(1:9),c(2,5,2))
a2
is.array(a2)
a2 <- array(c(1:9),c(2,5,1))
a2
is.array(a2)
(coerce6 <- matrix(1:9, nrow= 3))
is.matrix(coerce6)
(coerce5 <- as.numeric(c("1", "2", "3")))
typeof(coerce5)
(coerce6 <- matrix(1:9, nrow= 3))
is.matrix(coerce6)
(coerce7 <- as.data.frame(matrix(1:9, nrow= 3)))
is.data.frame(coerce7)
dfa <- cbind(vNumeric, vCharacter, vLogical)
dfa  # Matrix of one data type
df <- as.data.frame(cbind(vNumeric, vCharacter, vLogical))
df  # Makes a data frame with three different data types
(coerce7 <- as.data.frame(matrix(1:9, nrow= 3)))
is.data.frame(coerce7)
# Clear environment
rm(list = ls())
# Clear console
cat("\014")  # ctrl+L
v1
v1 <- Scan()
5
v1 <- Scan()
v1 <- Scan()
v1 <- scan()
v1
gc()
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("dplyr")) install.packages("dplyr")
if(!require("forecast")) install.packages("forecast")
#Loading dataset
df = read.csv("DHS_Daily_Report_2020.csv")
setwd("F:/Demand Forecasting Thesis/ARIMA, SARIMA, SARIMAX")
#Loading dataset
df = read.csv("DHS_Daily_Report_2020.csv")
#Transformation of Date variable into POSTXLT format and type format
df$Date = strptime(df$Date,
format = "%m/%d/%Y")
#Conversion of above POSTXLT format into date format
df$Date = as.Date(df$Date)
#Selecting specific columns from the data frame
df = df %>% select(Date,
Total.Individuals.in.Shelter,
Easter,
Thanksgiving,
Christmas,
Temperature)
#Changing the colname
colnames(df)[2] = "y"
#Plotting ggplot
ggplot(df, aes(x=df$Date, y=y))+
geom_line()+
xlab("Time")+
ylab("Shelter Demand")+
theme(text = element_text(size = 20))+
scale_x_date(date_labels = "%Y %b")
#Training Set and Test Set Division
#Since we have regressors as well and we want to include it as well, we will be doing in differnt format
training_set = df %>% filter(Date < "2020-12-01")
test_set = df %>% filter(Date >= "2020-12-01")
#Time Series object conversion
#7 or 365 if daily, if weekly 52, if monthly 12 months, if quarterly 4
training_y = ts(data=training_set$y,
frequency = 7)
#Auto-correlation plot
acf(training_y)
#Stationarity
#To find out how many times we have to do in order to make our data stationary
#ndiffs function stands for number of differences
#We don't have to do anything to make the model stationary the automated function of the ARIMA family will do it for us.
ndiffs(x=training_y, test = "adf")
#Storing or Isolating the regressors inside of a matrix
training_set_reg = as.matrix(training_set[,3:6])
test_Set_reg = as.matrix(training_set[,3:6])
#SARIMAX model
model = auto.arima(y= training_y,
stepwise = FALSE,
approximation = FALSE,
xreg = training_reg)
#SARIMAX model
model = auto.arima(y= training_y,
stepwise = FALSE,
approximation = FALSE,
xreg = training_set_reg)
#Auto-correlation plot
acf(training_y)
summary(model)
View(df)
#For removing out object, variables stored in current R session
rm(list = ls())
#To clear plot
dev.off()
#For clearing the console
cat("\014")
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("dplyr")) install.packages("dplyr")
if(!require("forecast")) install.packages("forecast")
#Loading dataset
df = read.csv("DHS_Daily_Report_2020.csv")
#Loading dataset
df = read.csv("DHS_Daily_Report_2020.csv")
#Transformation of Date variable into POSTXLT format and type format
df$Date = strptime(df$Date,
format = "%m/%d/%Y")
#Conversion of above POSTXLT format into date format
df$Date = as.Date(df$Date)
#Selecting specific columns from the data frame
df = df %>% select(Date,
Total.Individuals.in.Shelter,
Easter,
Thanksgiving,
Christmas,
Temperature)
#Changing the colname
colnames(df)[2] = "y"
#Plotting ggplot
ggplot(df, aes(x=df$Date, y=y))+
geom_line()+
xlab("Time")+
ylab("Shelter Demand")+
theme(text = element_text(size = 20))+
scale_x_date(date_labels = "%Y %b")
#Training Set and Test Set Division
#Since we have regressors as well and we want to include it as well, we will be doing in differnt format
training_set = df %>% filter(Date < "2020-12-01")
test_set = df %>% filter(Date >= "2020-12-01")
#Time Series object conversion
#7 or 365 if daily, if weekly 52, if monthly 12 months, if quarterly 4
training_y = ts(data=training_set$y,
frequency = 7)
#Auto-correlation plot
acf(training_y)
#Stationarity
#To find out how many times we have to do in order to make our data stationary
#ndiffs function stands for number of differences
#We don't have to do anything to make the model stationary the automated function of the ARIMA family will do it for us.
ndiffs(x=training_y, test = "adf")
#Storing or Isolating the regressors inside of a matrix
training_set_reg = as.matrix(training_set[,3:6])
test_Set_reg = as.matrix(training_set[,3:6])
#SARIMAX model
model = auto.arima(y= training_y,
stepwise = FALSE,
approximation = FALSE,
xreg = training_set_reg)
summary(model)
#Forecasting
predictions_sarimax = forecast(model, xreg = test_Set_reg)
#Plotting
autoplot(predictions_sarimax)
#Storing or Isolating the regressors inside of a matrix
training_set_reg = as.matrix(training_set[,3:6])
test_set_reg = as.matrix(test_set[,3:6])
#For removing out object, variables stored in current R session
rm(list = ls())
#To clear plot
dev.off()
#For clearing the console
cat("\014")
if(!require("ggplot2")) install.packages("ggplot2")
if(!require("dplyr")) install.packages("dplyr")
if(!require("forecast")) install.packages("forecast")
#Loading dataset
df = read.csv("DHS_Daily_Report_2020.csv")
#Transformation of Date variable into POSTXLT format and type format
df$Date = strptime(df$Date,
format = "%m/%d/%Y")
#Conversion of above POSTXLT format into date format
df$Date = as.Date(df$Date)
#Selecting specific columns from the data frame
df = df %>% select(Date,
Total.Individuals.in.Shelter,
Easter,
Thanksgiving,
Christmas,
Temperature)
#Changing the colname
colnames(df)[2] = "y"
#Plotting ggplot
ggplot(df, aes(x=df$Date, y=y))+
geom_line()+
xlab("Time")+
ylab("Shelter Demand")+
theme(text = element_text(size = 20))+
scale_x_date(date_labels = "%Y %b")
#Training Set and Test Set Division
#Since we have regressors as well and we want to include it as well, we will be doing in differnt format
training_set = df %>% filter(Date < "2020-12-01")
test_set = df %>% filter(Date >= "2020-12-01")
#Time Series object conversion
#7 or 365 if daily, if weekly 52, if monthly 12 months, if quarterly 4
training_y = ts(data=training_set$y,
frequency = 7)
#Auto-correlation plot
acf(training_y)
#Stationarity
#To find out how many times we have to do in order to make our data stationary
#ndiffs function stands for number of differences
#We don't have to do anything to make the model stationary the automated function of the ARIMA family will do it for us.
ndiffs(x=training_y, test = "adf")
#Storing or Isolating the regressors inside of a matrix
training_set_reg = as.matrix(training_set[,3:6])
test_set_reg = as.matrix(test_set[,3:6])
#SARIMAX model
model = auto.arima(y= training_y,
stepwise = FALSE,
approximation = FALSE,
xreg = training_set_reg)
summary(model)
#Forecasting
predictions_sarimax = forecast(model, xreg = test_Set_reg)
#Plotting
autoplot(predictions_sarimax)
#Forecasting
predictions_sarimax = forecast(model, xreg = test_Set_reg)
#Forecasting
predictions_sarimax = forecast(model, xreg = test_set_reg)
#Plotting
autoplot(predictions_sarimax)
#Accuracy
accuracy(predcitions_sarimax, test_set)
#Accuracy
accuracy(predictions_sarimax, test_set)
#Accuracy
accuracy(predictions_sarimax$mean, test_set$y)
#Saving our forecast
sarimax = as.data.frame(predictions_sarimax)
View(predictions_sarimax)
#Saving our forecast
sarimax = as.data.frame(predictions_sarimax$mean)
View(predictions_sarimax)
View(sarimax)
#Saving our forecast
sarimax = as.data.frame(predictions_sarimax)
View(sarimax)
#Saving our forecast
sarimax = as.data.frame(predictions_sarimax$mean)
View(predictions_sarimax)
View(sarimax)
colnames(sarimax)[1] = "SARIMAX"
write.csv(sarimax,
file = "Saving Forecast/Sarima.csv",
row.names = FALSE ) #rownames set to false since we dont want any row name
#Time Series object conversion
#7 or 365 if daily, if weekly 52, if monthly 12 months, if quarterly 4
training_y = ts(data=training_set$y,
frequency = 365.5)
#Auto-correlation plot
acf(training_y)
#Plotting
autoplot(predictions_sarimax)
#Plotting ggplot
ggplot(df, aes(x=df$Date, y=y))+
geom_line()+
xlab("Time")+
ylab("Shelter Demand")+
theme(text = element_text(size = 20))+
scale_x_date(date_labels = "%Y %b")
